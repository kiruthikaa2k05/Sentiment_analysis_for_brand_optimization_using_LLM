# -*- coding: utf-8 -*-
"""IP_FINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/179aWnIZNLOfjOwIaHfdPgo_KT98Dq-8q
"""



"""THIS IS NEW **CODE**"""

# Import necessary libraries
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from sklearn.feature_extraction.text import CountVectorizer
from collections import Counter
from sklearn.decomposition import LatentDirichletAllocation
import plotly.express as px
import openai  # For advanced LLM integration (optional)
import logging
from datetime import datetime  # For time-series analysis

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Step 1: Load Dataset
try:
    df = pd.read_csv('/content/flipkart_product.csv',encoding='latin-1')  # Ensure your dataset has 'Review', 'Brand', and 'Timestamp' columns
    logging.info("Dataset loaded successfully!")
except FileNotFoundError:
    logging.error("Error: Dataset file not found. Please check the file path.")
    exit()

# üîÑ Standardize Column Names Immediately After Loading
df.columns = df.columns.str.strip().str.lower()

# ‚úÖ Verify Column Names
print("Available Columns in DataFrame:", df.columns.tolist())

# Step 2: Data Preprocessing
def preprocess_text(text):
    # Convert to string to handle non-string values
    text = str(text) # Convert to string explicitly
    # Remove special characters, URLs, and mentions
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'\@\w+|\#', '', text)
    text = re.sub(r'[^A-Za-z0-9 ]+', '', text)
    return text.strip().lower()

# Access the column using its lowercase name 'review'
df['Cleaned_Review'] = df['review'].apply(preprocess_text)

# Step 3: Fine-Tune a Sentiment Analysis Model (Optional)
# Load a pre-trained model and tokenizer
model_name = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# Fine-tune the model on your dataset (example)
# Note: You need labeled data for fine-tuning
def fine_tune_model(train_texts, train_labels):
    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)
    train_dataset = torch.utils.data.TensorDataset(
        torch.tensor(train_encodings['input_ids']),
        torch.tensor(train_encodings['attention_mask']),
        torch.tensor(train_labels)
    )
    training_args = TrainingArguments(
        output_dir='./results',
        num_train_epochs=3,
        per_device_train_batch_size=16,
        logging_dir='./logs',
    )
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
    )
    trainer.train()
    return model

# Initialize the sentiment analyzer
sentiment_analyzer = pipeline("sentiment-analysis")  # Or load your fine-tuned model

# Add this line at the beginning of the code where the KeyError occurred
if 'Cleaned_Review' not in df.columns:
    df['Cleaned_Review'] = df['review'].astype(str).apply(preprocess_text) # Assuming preprocess_text is defined

# Existing code
# Analyze sentiment
def analyze_sentiment(text):
    result = sentiment_analyzer(text)[0]
    return result['label'], result['score']

df[['Sentiment', 'Confidence']] = df['Cleaned_Review'].apply(
    lambda x: pd.Series(analyze_sentiment(x))
)

# ‚úÖ Step 3: Create 'brand' Column from 'productname'
df['brand'] = df['productname'].apply(lambda x: x.split()[0] if isinstance(x, str) else 'Unknown')

# üîç Verify if 'brand' column was created successfully
print("Unique Brands Extracted:", df['brand'].unique())

df.columns = df.columns.str.lower().str.strip()  # Convert to lowercase and remove extra spaces
print("Cleaned Columns:", df.columns.tolist())

print("Missing values in 'brand':", df['brand'].isnull().sum())
print("Missing values in 'sentiment':", df['sentiment'].isnull().sum())

print("Available Columns in DataFrame:", df.columns.tolist())

import matplotlib.pyplot as plt
import seaborn as sns

# ‚úÖ Check if 'brand' and 'sentiment' columns exist
if 'brand' in df.columns and 'sentiment' in df.columns:
    # Get Top 10 Brands by Review Count
    top_brands = df['brand'].value_counts().nlargest(10).index
    df_top = df[df['brand'].isin(top_brands)]

    # Count sentiments for each brand
    sentiment_counts = df_top.groupby(['brand', 'sentiment']).size().reset_index(name='count')

    # Pivot for plotting
    sentiment_pivot = sentiment_counts.pivot(index='brand', columns='sentiment', values='count').fillna(0)
    sentiment_pivot_percent = sentiment_pivot.div(sentiment_pivot.sum(axis=1), axis=0) * 100

    # ‚úÖ Plot: Horizontal Stacked Bar Chart (Only one plot now)
    sentiment_pivot_percent.sort_values(by='POSITIVE', ascending=False).plot(
        kind='barh',
        stacked=True,
        figsize=(12, 8),
        colormap='coolwarm',
        edgecolor='black'
    )

    plt.title('Sentiment Distribution by Top 10 Brands', fontsize=16)
    plt.xlabel('Percentage of Sentiments', fontsize=12)
    plt.ylabel('Brand', fontsize=12)
    plt.legend(title='Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    plt.show()
else:
    print("‚ùå 'brand' or 'sentiment' column not found in the dataset.")

from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt

# ‚úÖ Combine stopwords with WordCloud defaults
stopwords = set(STOPWORDS)

# ‚úÖ Separate Positive and Negative Reviews
# Use 'Sentiment' (capital S) to access the correct column
positive_reviews = df[df['sentiment'] == 'POSITIVE']['review'].dropna().str.cat(sep=' ')
negative_reviews = df[df['sentiment'] == 'NEGATIVE']['review'].dropna().str.cat(sep=' ')

# ‚úÖ Generate Word Clouds
positive_wc = WordCloud(width=800, height=400, background_color='white', stopwords=stopwords, colormap='Greens').generate(positive_reviews)
negative_wc = WordCloud(width=800, height=400, background_color='white', stopwords=stopwords, colormap='Reds').generate(negative_reviews)

# ‚úÖ Plot Word Clouds
fig, axs = plt.subplots(1, 2, figsize=(20, 10))

# Positive Word Cloud
axs[0].imshow(positive_wc, interpolation='bilinear')
axs[0].set_title('üåü Positive Reviews Word Cloud', fontsize=20)
axs[0].axis('off')

# Negative Word Cloud
axs[1].imshow(negative_wc, interpolation='bilinear')
axs[1].set_title('‚ö° Negative Reviews Word Cloud', fontsize=20)
axs[1].axis('off')

plt.tight_layout()
plt.show()

# Step 5: Topic Modeling (LDA)
# Ensure 'Cleaned_Review' column exists
if 'Cleaned_Review' not in df.columns:
    # Assuming preprocess_text function is already defined
    # Convert column name to lowercase for access
    df['Cleaned_Review'] = df['review'].astype(str).apply(preprocess_text)

vectorizer = CountVectorizer(stop_words='english', max_features=1000)
X = vectorizer.fit_transform(df['Cleaned_Review'])

# Apply Latent Dirichlet Allocation (LDA)
lda = LatentDirichletAllocation(n_components=5, random_state=42)
lda.fit(X)

# Display topics
def display_topics(model, feature_names, no_top_words):
    for topic_idx, topic in enumerate(model.components_):
        print(f"Topic {topic_idx + 1}:")
        print(" ".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))

display_topics(lda, vectorizer.get_feature_names_out(), no_top_words=10)

